{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from subprocess import Popen, PIPE\n",
    "import json\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setEnv(spark_home):    \n",
    "    if not spark_home:\n",
    "     raise ValueError('SPARK_HOME environment variable is not set')\n",
    "    os.environ['SPARK_HOME']=spark_home\n",
    "    sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "    sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.8.2.1-src.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSC(master, appName='test', cores='10', mem='10g'):\n",
    "    if not master:\n",
    "        raise ValueError('master is not set')\n",
    "    sparkEnv={\"spark.cores.max\":cores,\n",
    "              \"spark.driver.memory\":\"5g\",\n",
    "              \"spark.executor.memory\":mem}\n",
    "    conf = SparkConf()\n",
    "    conf.setMaster(master)\n",
    "    conf.setAppName(appName)\n",
    "    conf.setAll([(x,sparkEnv[x]) for x in sparkEnv])\n",
    "    sc = SparkContext(conf=conf)\n",
    "    sqlContext = HiveContext(sc)\n",
    "    \n",
    "    return sc, sqlContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "setEnv('/opt/spark-1.4.3-bin-cdh4')\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import HiveContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import udf \n",
    "from pyspark.sql.types import *\n",
    "from py4j.java_gateway import Py4JJavaError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc, sqlContext=getSC('spark://bi-hd03.vpon.idc:7077','hive',cores='80',mem='10g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a hive table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql='select * from ad_tw limit 1'\n",
    "process = Popen(['hive','-e',sql],stdout=PIPE, stderr=PIPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stdout, stderr = process.communicate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process.poll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_hive_table(sql):\n",
    "    process = Popen(['hive','-e',sql],stdout=PIPE, stderr=PIPE)\n",
    "    stdout, stderr = process.communicate() \n",
    "    if process.poll() == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return stderr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_file_hive_table(tablename, path):\n",
    "    process = Popen(['hive','-e','load data local inpath \"%s\" into table %s' % (path,tablename)],stdout=PIPE, stderr=PIPE)\n",
    "    stdout, stderr = process.communicate() \n",
    "    if process.poll() == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return stderr \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def select_hive_table(sql):\n",
    "    process = Popen(['hive','-e',sql],stdout=PIPE, stderr=PIPE)\n",
    "    stdout, stderr = process.communicate() \n",
    "    if process.poll() == 0:\n",
    "        return stdout\n",
    "    else:\n",
    "        return stderr \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/home/bryan/workspace/SparkTutorial/data/titanic.txt', quotechar='\"', names=['id','survival','pclass','name','sex','age','sibsp','parch','ticket','fare','cabin','embarked'])\n",
    "df.to_csv('/home/bryan/workspace/SparkTutorial/data/titanic2.txt', sep=':', header=False, index=Fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"create table temp.titanic \n",
    "(\n",
    "id  int,\n",
    "survival int,\n",
    "pclass int,\n",
    "name String,\n",
    "sex String,\n",
    "age int,\n",
    "sibsp int,\n",
    "parch int,\n",
    "ticket  String,\n",
    "fare String,\n",
    "cabin String,\n",
    "embarked String\n",
    ")ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ':'\n",
    "LINES TERMINATED BY '\\n'\n",
    "\"\"\"\n",
    "\n",
    "create_hive_table(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_file_hive_table('temp.titanic', '/home/bryan/workspace/SparkTutorial/data/titanic2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1\\t0\\t3\\tBraund, Mr. Owen Harris\\tmale\\tNULL\\t1\\t0\\tA/5 21171\\t7.25\\t\\tS\\n2\\t1\\t1\\tCumings, Mrs. John Bradley (Florence Briggs Thayer)\\tfemale\\tNULL\\t1\\t0\\tPC 17599\\t71.2833\\tC85\\tC\\n3\\t1\\t3\\tHeikkinen, Miss. Laina\\tfemale\\tNULL\\t0\\t0\\tSTON/O2. 3101282\\t7.925\\t\\tS\\n4\\t1\\t1\\tFutrelle, Mrs. Jacques Heath (Lily May Peel)\\tfemale\\tNULL\\t1\\t0\\t113803\\t53.1\\tC123\\tS\\n5\\t0\\t3\\tAllen, Mr. William Henry\\tmale\\tNULL\\t0\\t0\\t373450\\t8.05\\t\\tS\\n6\\t0\\t3\\tMoran, Mr. James\\tmale\\tNULL\\t0\\t0\\t330877\\t8.4583\\t\\tQ\\n7\\t0\\t1\\tMcCarthy, Mr. Timothy J\\tmale\\tNULL\\t0\\t0\\t17463\\t51.8625\\tE46\\tS\\n8\\t0\\t3\\tPalsson, Master. Gosta Leonard\\tmale\\tNULL\\t3\\t1\\t349909\\t21.075\\t\\tS\\n9\\t1\\t3\\tJohnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)\\tfemale\\tNULL\\t0\\t2\\t347742\\t11.1333\\t\\tS\\n10\\t1\\t2\\tNasser, Mrs. Nicholas (Adele Achem)\\tfemale\\tNULL\\t1\\t0\\t237736\\t30.0708\\t\\tC\\n'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_hive_table('select * from temp.titanic limit 10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## interact with hive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = sqlContext.sql(\"select * from temp.titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|id|survival|pclass|                name|   sex| age|sibsp|parch|          ticket|   fare|cabin|embarked|\n",
      "+--+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "| 1|       0|     3|Braund, Mr. Owen ...|  male|  22|    1|    0|       A/5 21171|   7.25|     |       S|\n",
      "| 2|       1|     1|Cumings, Mrs. Joh...|female|  38|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "| 3|       1|     3|Heikkinen, Miss. ...|female|  26|    0|    0|STON/O2. 3101282|  7.925|     |       S|\n",
      "| 4|       1|     1|Futrelle, Mrs. Ja...|female|  35|    1|    0|          113803|   53.1| C123|       S|\n",
      "| 5|       0|     3|Allen, Mr. Willia...|  male|  35|    0|    0|          373450|   8.05|     |       S|\n",
      "| 6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583|     |       Q|\n",
      "| 7|       0|     1|McCarthy, Mr. Tim...|  male|  54|    0|    0|           17463|51.8625|  E46|       S|\n",
      "| 8|       0|     3|Palsson, Master. ...|  male|   2|    3|    1|          349909| 21.075|     |       S|\n",
      "| 9|       1|     3|Johnson, Mrs. Osc...|female|  27|    0|    2|          347742|11.1333|     |       S|\n",
      "|10|       1|     2|Nasser, Mrs. Nich...|female|  14|    1|    0|          237736|30.0708|     |       C|\n",
      "|11|       1|     3|Sandstrom, Miss. ...|female|   4|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|12|       1|     1|Bonnell, Miss. El...|female|  58|    0|    0|          113783|  26.55| C103|       S|\n",
      "|13|       0|     3|Saundercock, Mr. ...|  male|  20|    0|    0|       A/5. 2151|   8.05|     |       S|\n",
      "|14|       0|     3|Andersson, Mr. An...|  male|  39|    1|    5|          347082| 31.275|     |       S|\n",
      "|15|       0|     3|Vestrom, Miss. Hu...|female|  14|    0|    0|          350406| 7.8542|     |       S|\n",
      "|16|       1|     2|Hewlett, Mrs. (Ma...|female|  55|    0|    0|          248706|   16.0|     |       S|\n",
      "|17|       0|     3|Rice, Master. Eugene|  male|   2|    4|    1|          382652| 29.125|     |       Q|\n",
      "|18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0|     |       S|\n",
      "|19|       0|     3|Vander Planke, Mr...|female|  31|    1|    0|          345763|   18.0|     |       S|\n",
      "|20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225|     |       C|\n",
      "+--+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'survival',\n",
       " 'pclass',\n",
       " 'name',\n",
       " 'sex',\n",
       " 'age',\n",
       " 'sibsp',\n",
       " 'parch',\n",
       " 'ticket',\n",
       " 'fare',\n",
       " 'cabin',\n",
       " 'embarked']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create dimension table\n",
    "part1 = sqlContext.sql(\"select id, survival, pclass from temp.titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "part2 = sqlContext.sql(\"select id, sex, age from temp.titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# register temp table\n",
    "part1.registerTempTable('part1')\n",
    "part2.registerTempTable('part2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--+--------+------+\n",
      "|id|survival|pclass|\n",
      "+--+--------+------+\n",
      "| 1|       0|     3|\n",
      "| 2|       1|     1|\n",
      "| 3|       1|     3|\n",
      "| 4|       1|     1|\n",
      "| 5|       0|     3|\n",
      "| 6|       0|     3|\n",
      "| 7|       0|     1|\n",
      "| 8|       0|     3|\n",
      "| 9|       1|     3|\n",
      "|10|       1|     2|\n",
      "|11|       1|     3|\n",
      "|12|       1|     1|\n",
      "|13|       0|     3|\n",
      "|14|       0|     3|\n",
      "|15|       0|     3|\n",
      "|16|       1|     2|\n",
      "|17|       0|     3|\n",
      "|18|       1|     2|\n",
      "|19|       0|     3|\n",
      "|20|       1|     3|\n",
      "+--+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use as a Hive table\n",
    "sqlContext.sql(\"select * from part1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+---+------+----+\n",
      "| id|survival|pclass| id|   sex| age|\n",
      "+---+--------+------+---+------+----+\n",
      "|631|       1|     1|631|  male|  80|\n",
      "|831|       1|     3|831|female|  15|\n",
      "| 31|       0|     1| 31|  male|  40|\n",
      "|231|       1|     1|231|female|  35|\n",
      "|431|       1|     1|431|  male|  28|\n",
      "|632|       0|     3|632|  male|  51|\n",
      "|832|       1|     2|832|  male|   0|\n",
      "| 32|       1|     1| 32|female|null|\n",
      "|232|       0|     3|232|  male|  29|\n",
      "|432|       1|     3|432|female|null|\n",
      "|633|       1|     1|633|  male|  32|\n",
      "|833|       0|     3|833|  male|null|\n",
      "| 33|       1|     3| 33|female|null|\n",
      "|233|       0|     2|233|  male|  59|\n",
      "|433|       1|     2|433|female|  42|\n",
      "|634|       0|     1|634|  male|null|\n",
      "|834|       0|     3|834|  male|  23|\n",
      "| 34|       0|     2| 34|  male|  66|\n",
      "|234|       1|     3|234|female|   5|\n",
      "|434|       0|     3|434|  male|  17|\n",
      "+---+--------+------+---+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"select * from part1 a join part2 b on a.id = b.id \").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use sql as rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=1, survival=0, pclass=3),\n",
       " Row(id=2, survival=1, pclass=1),\n",
       " Row(id=3, survival=1, pclass=3),\n",
       " Row(id=4, survival=1, pclass=1),\n",
       " Row(id=5, survival=0, pclass=3)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part1.rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part1.map(lambda x: x[0]).take(5)part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 184), (1, 216), (3, 491)]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RDD operate\n",
    "part1.map(lambda x: (x[2],1)).reduceByKey(lambda x, y: x+y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|pclass|count|\n",
      "+------+-----+\n",
      "|     1|  216|\n",
      "|     2|  184|\n",
      "|     3|  491|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sql operate\n",
    "part1.groupby('pclass').count().show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|pclass|COUNT(pclass)|\n",
      "+------+-------------+\n",
      "|     1|          216|\n",
      "|     2|          184|\n",
      "|     3|          491|\n",
      "+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "part1.groupBy('pclass').agg({'pclass':'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|COUNT(pclass)|\n",
      "+-------------+\n",
      "|          891|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "part1.agg({'pclass':'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|          AVG(age)|\n",
      "+------------------+\n",
      "|29.679271708683473|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "part2.agg({'age':'avg'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|   sex|          AVG(age)|\n",
      "+------+------------------+\n",
      "|female|27.904214559386972|\n",
      "|  male| 30.70198675496689|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "part2.groupBy('sex').agg({'age':'avg'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDD to Sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "part2_rdd = part2.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(part2_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=1, sex=u'male', age=22),\n",
       " Row(id=2, sex=u'female', age=38),\n",
       " Row(id=3, sex=u'female', age=26),\n",
       " Row(id=4, sex=u'female', age=35),\n",
       " Row(id=5, sex=u'male', age=35)]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part2_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, u'male', 22],\n",
       " [2, u'female', 38],\n",
       " [3, u'female', 26],\n",
       " [4, u'female', 35],\n",
       " [5, u'male', 35]]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace male to 0, female to 1\n",
    "part2_rdd.map(lambda x: [i for i in x]).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coding = {'male':0,\n",
    "          'female':1}\n",
    "def recode(x):\n",
    "    return coding[x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "part2_rdd = part2_rdd.map(lambda x: [x[0], recode(x[1]), x[2]]).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "     \n",
    "fields = [StructField('id',IntegerType(),True ), \\\n",
    "          StructField('gender', IntegerType(), True), \\\n",
    "          StructField('age', IntegerType(), True)]\n",
    "    \n",
    "schema = StructType(fields)\n",
    "    \n",
    "part2_rdd_df = sqlContext.createDataFrame(part2_rdd, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(part2_rdd_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User define Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf \n",
    "sqlContext.registerFunction(\"recode\", lambda x: recode(x), IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|   sex|_c1|\n",
      "+------+---+\n",
      "|  male|  0|\n",
      "|female|  1|\n",
      "|female|  1|\n",
      "|female|  1|\n",
      "|  male|  0|\n",
      "|  male|  0|\n",
      "|  male|  0|\n",
      "|  male|  0|\n",
      "|female|  1|\n",
      "|female|  1|\n",
      "|female|  1|\n",
      "|female|  1|\n",
      "|  male|  0|\n",
      "|  male|  0|\n",
      "|female|  1|\n",
      "|female|  1|\n",
      "|  male|  0|\n",
      "|  male|  0|\n",
      "|female|  1|\n",
      "|female|  1|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"select sex, recode(sex) from temp.titanic\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## save to Hive table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- survival: integer (nullable = true)\n",
      " |-- pclass: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sibsp: integer (nullable = true)\n",
      " |-- parch: integer (nullable = true)\n",
      " |-- ticket: string (nullable = true)\n",
      " |-- fare: string (nullable = true)\n",
      " |-- cabin: string (nullable = true)\n",
      " |-- embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"create table temp.titanic2\n",
    "(\n",
    "id  int,\n",
    "survival int,\n",
    "pclass int,\n",
    "name String,\n",
    "sex String,\n",
    "age int,\n",
    "sibsp int,\n",
    "parch int,\n",
    "ticket  String,\n",
    "fare String,\n",
    "cabin String,\n",
    "embarked String\n",
    ")ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ':'\n",
    "LINES TERMINATED BY '\\n'\n",
    "\"\"\"\n",
    "\n",
    "create_hive_table(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.repartition(10)\n",
    "sqlContext.sql(\"use temp\")\n",
    "df.write.insertInto('titanic2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: org.apache.hadoop.metrics.jvm.EventCounter is deprecated. Please use org.apache.hadoop.log.metrics.EventCounter in all the log4j.properties files.\n",
      "Logging initialized using configuration in file:/etc/hive/conf/hive-log4j.properties\n",
      "Hive history file=/tmp/bryan/hive_job_log_2c59fb2c-0d09-4d2e-9995-8271c998415f_1412742059.txt\n",
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/usr/lib/hadoop/lib/camus-example-0.1.0-SNAPSHOT-shaded.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/usr/lib/zookeeper/lib/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "OK\n",
      "121\t0\t2\tHickman, Mr. Stanley George\tmale\t21\t2\t0\tS.O.C. 14879\t73.5\t\tS\n",
      "603\t0\t1\tHarrington, Mr. Charles H\tmale\tNULL\t0\t0\t113796\t42.4\t\tS\n",
      "317\t1\t2\tKantor, Mrs. Sinai (Miriam Sternin)\tfemale\t24\t1\t0\t244367\t26.0\t\tS\n",
      "841\t0\t3\tAlhomaki, Mr. Ilmari Rudolf\tmale\t20\t0\t0\tSOTON/O2 3101287\t7.925\t\tS\n",
      "83\t1\t3\tMcDermott, Miss. Brigdet Delia\tfemale\tNULL\t0\t0\t330932\t7.7875\t\tQ\n",
      "130\t0\t3\tEkstrom, Mr. Johan\tmale\t45\t0\t0\t347061\t6.975\t\tS\n",
      "239\t0\t2\tPengelly, Mr. Frederick William\tmale\t19\t0\t0\t28665\t10.5\t\tS\n",
      "755\t1\t2\tHerman, Mrs. Samuel (Jane Laver)\tfemale\t48\t1\t2\t220845\t65.0\t\tS\n",
      "487\t1\t1\tHoyt, Mrs. Frederick Maxfield (Jane Anne Forby)\tfemale\t35\t1\t0\t19943\t90.0\tC93\tS\n",
      "610\t1\t1\tShutes, Miss. Elizabeth W\tfemale\t40\t0\t0\tPC 17582\t153.4625\tC125\tS\n",
      "Time taken: 1.214 seconds\n"
     ]
    }
   ],
   "source": [
    "!hive -e \"select * from temp.titanic2 limit 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
